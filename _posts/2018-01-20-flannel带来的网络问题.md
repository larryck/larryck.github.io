---
title: flannel带来的网络问题
description: 
categories:
- k8s
tags:
- network
---

问题是在稳定性测试过程中发现的。当我们使用wrk为k8s平台上运行的nginx打压测试时，系统中某一个核的softirqd cpu利用率非常高，其他核的利用率都比较低；而通过wrk向执行在k8s平台之外的nginx打压测试时，各个核的softirqd cpu 利用率分布比较平均。本文分析了问题的所在。

# 问题描述
wrk的执行命令如下：
> ./wrk -c 100 -d 50 -t 24 http://192.168.1.2:31235

其中，nginx在k8s平台以Deployment部署，pod个数为40个，pod均匀分布在node1、node2、node3三个节点上。其中，192.168.1.2是node2节点的地址。31235是nginx对应service的NodePort。

我们使用top命令观察各个节点的cpu利用率时可以发现，node1的softirqd0 cpu利用率接近40%，其余softirqd cpu利用率小于5%；node2 softirqd0 cpu利用率接近90%，其余softirqd cpu利用率小于5%；node3 softirqd0 cpu利用率接近40%，其余softirqd cpu利用率小于5%。这肯定是个问题。

# 中断分布
我们首先从中断分布入手。以node1为例，是否是因为所有的网络中断都集中在cpu0上导致的这个问题？

通过查看/proc/interrupts可以看到，网卡eno1是一个多队列网卡，中断号分布在64-71，我们看到所有的中断都集中在cpu0上，而其他CPU上这些中断的次数为0。中断分布肯定是问题之一。

通过修改/proc/irq/64-71/smp_affinity文件，将中断分布到各个cpu核上。再次测试我们发现了新的现象。此时，node1的softirqd7 cpu利用率接近40%，其他softirqd利用率小于5%；node2的softirqd2和softirqd5 cpu利用率接近40%，其他softirqd利用率小于5%；node3的softirqd0 cpu利用率接近40%，其他softirqd利用率小于5%。再看/proc/interrupt，发现eno1上中断已经分布在各个核上，但是cpu7的中断数为其他cpu的数倍。可见，中断分布并不是全部问题所在。

# 网络软中断处理
我们再分析一下这些软中断在做什么。还是以node1为例，从/proc/softirqs中我们可以发现，cpu7的主要软中断工作是NET_RX中断，这符合我们的预期。而对应的网络流量网卡通道8带来的流量，也就是说网卡通道8的NET_RX所有的流量都交由cpu7处理，才导致CPU7的softirqd CPU利用相比其他softirqd高很多。

通过修改/sys/class/net/eno1/queues/rx-7/rps_cpus将通道8的NET_RX交由多个核处理。再次测试发现，各个核的softirqd cpu利用率可以平均分布。

# flannel带来的问题
接下来的问题是，在node1上网络流量为什么会集中在通道8上？

咨询了网络方面的同事，我得知以下信息：多队列网卡会根据网络包五元组决定网络包由哪个通道处理。想到这些我们回头看看flannel的设计：flannel使用overlay网络，基于vxlan，两个节点之间的网络包使用固定ip以及固定的端口，多队列网卡自然就将所有的网络包推到同一个队列处理了。

接下来，我将研究如何将flannel的网络包分散到各个网卡队列中。

